{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CnefNuj9DsDx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = kagglehub.dataset_download(\"benroshan/online-food-delivery-preferencesbangalore-region\")\n",
        "\n",
        "print(\"Path to dataset files:\", d2)\n",
        "\n",
        "d5 = kagglehub.dataset_download(\"saurabhbadole/zomato-delivery-operations-analytics-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", d5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOh2jphqEY0H",
        "outputId": "ab64e1ae-723f-4714-beeb-7bd3e866e018"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/benroshan/online-food-delivery-preferencesbangalore-region?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24.0k/24.0k [00:00<00:00, 11.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/benroshan/online-food-delivery-preferencesbangalore-region/versions/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/saurabhbadole/zomato-delivery-operations-analytics-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.43M/1.43M [00:00<00:00, 105MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/saurabhbadole/zomato-delivery-operations-analytics-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 5"
      ],
      "metadata": {
        "id": "J505fiAeH62N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_5 = pd.read_csv(\"/root/.cache/kagglehub/datasets/saurabhbadole/zomato-delivery-operations-analytics-dataset/versions/1/Zomato Dataset.csv\")"
      ],
      "metadata": {
        "id": "alDcYA-kEm09"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For column Time_Orderd, remove Nan, 0.x and 1 values:"
      ],
      "metadata": {
        "id": "lRDtDpYjHsb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_5 = df_5[~df_5['Time_Orderd'].apply(lambda x: isinstance(x, float) or '0.' in str(x) or str(x) == '1')]"
      ],
      "metadata": {
        "id": "RlgdSHpdHxxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For column Time_Order_picked, remove 0.x and 1 values:"
      ],
      "metadata": {
        "id": "p4ZknBz9Hthg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_5 = df_5[~df_5['Time_Order_picked'].apply(lambda x: '0.' in str(x) or str(x) == '1' or '24:' in str(x))]"
      ],
      "metadata": {
        "id": "TZ-jQVA1H1LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning Dataset D5"
      ],
      "metadata": {
        "id": "w2ULTpUkHjEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_5_cleaned = df_5.dropna()"
      ],
      "metadata": {
        "id": "j_G-gsOKErhP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D5 is now cleaned!"
      ],
      "metadata": {
        "id": "RrWWWHToIDms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a new dataset by simulation: Generate 34326 values of date and time"
      ],
      "metadata": {
        "id": "qNNWHT9QIHR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 34326\n",
        "from datetime import datetime, timedelta\n",
        "# Define the start and end dates\n",
        "start_date = \"2022-04-01\"\n",
        "end_date = \"2024-03-31\"\n",
        "# Create a range of dates\n",
        "date_range = pd.date_range(start=start_date, end=end_date)\n",
        "# Sample random dates from the range\n",
        "random_dates = np.random.choice(date_range, size=num_rows, replace=True)\n",
        "# Create a DataFrame with the random dates\n",
        "df_5_new = pd.DataFrame(random_dates, columns=['Date'])\n",
        "# Add a random time component to each date\n",
        "df_5_new['Date'] = df_5_new['Date'] + pd.to_timedelta(np.random.randint(0, 24 * 60 * 60, size=len(df_5_new)), unit='s')\n"
      ],
      "metadata": {
        "id": "NaQlm4rEE1La"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split above generated data into 2 new columns Order_Date and Time_Orderd:"
      ],
      "metadata": {
        "id": "eASr_OcDISFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Date' column is already a datetime type\n",
        "\n",
        "# Extract date and time components using vectorized operations\n",
        "df_5_new['Order_Date'] = df_5_new['Date'].dt.strftime(\"%d-%m-%Y\")\n",
        "df_5_new['Time_Orderd'] = df_5_new['Date'].dt.strftime(\"%H:%M\")\n",
        "\n",
        "df_5_new = df_5_new.drop('Date', axis=1)\n"
      ],
      "metadata": {
        "id": "HqXcdqy4FPh1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop existing column Date as it is not needed now:"
      ],
      "metadata": {
        "id": "Zuw5wXQ2IXHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_5_new = df_5_new.drop('Date', axis=1)"
      ],
      "metadata": {
        "id": "r4OWjJ9vIeDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate new column Time_Order_picked based on Time_Orderd column:"
      ],
      "metadata": {
        "id": "O0X3S10cIhFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_random_minutes(time_str):\n",
        "    # Convert 'time_ordered' to a datetime object\n",
        "    time_obj = pd.to_datetime(time_str, format='%H:%M')\n",
        "\n",
        "    # Generate a random value between 5 and 30 (minutes)\n",
        "    random_minutes = np.random.randint(5, 31)\n",
        "\n",
        "    # Add the random minutes to the time\n",
        "    new_time_obj = time_obj + pd.Timedelta(minutes=random_minutes)\n",
        "\n",
        "    if new_time_obj.hour == 24:\n",
        "        new_time_obj = new_time_obj.replace(hour=0, minute=new_time_obj.minute)\n",
        "\n",
        "    # Return the new time as a string in HH:MM format\n",
        "    return new_time_obj.strftime('%H:%M')\n",
        "# Create a new column with the random added minutes\n",
        "df_5_new['Time_Order_picked'] = df_5_new['Time_Orderd'].apply(add_random_minutes)"
      ],
      "metadata": {
        "id": "OCqRPw_mFBO9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate new column Weather_conditions:"
      ],
      "metadata": {
        "id": "wsfYMjEtI8dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of possible weather conditions\n",
        "weather_conditions = ['Windy','Sandstorms', 'Fog', 'Stormy', 'Cloudy', 'Rainy', 'Sunny']\n",
        "weather_frequencies = [10, 5, 5, 15, 15, 30, 50]\n",
        "# Randomly assign weather conditions to the 'weather' column\n",
        "df_5_new['Weather_conditions'] = np.random.choice(weather_conditions, size=num_rows, p=np.array(weather_frequencies) / sum(weather_frequencies))"
      ],
      "metadata": {
        "id": "e-LsOkUlE5JC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now generated a new dataset with required values!"
      ],
      "metadata": {
        "id": "4pWGrUZbJOom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to merge df_5 and df_5_new:"
      ],
      "metadata": {
        "id": "77nX2B6KJP-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_5 = pd.DataFrame()\n",
        "\n",
        "df_5_columns = ['Order_Date', 'Time_Orderd',  'Time_Order_picked',  'Weather_conditions']\n",
        "final_df_5_columns = ['Order_Date', 'Time_Orderd',  'Time_Order_picked',  'Weather_conditions']\n",
        "\n",
        "final_df_5[final_df_5_columns] = df_5_new[df_5_columns].copy()\n",
        "\n",
        "final_df_5 = pd.concat([final_df_5, df_5_new], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "TshPABbxFkGD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle final dataset"
      ],
      "metadata": {
        "id": "WLn_HZYmJdkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the rows\n",
        "final_df_5 = final_df_5.sample(frac=1, random_state=42)  # frac=1 means sample all rows"
      ],
      "metadata": {
        "id": "Gc7PVrISJoH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset D2"
      ],
      "metadata": {
        "id": "pZaUl5dIJwuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = pd.read_csv(\"/root/.cache/kagglehub/datasets/benroshan/online-food-delivery-preferencesbangalore-region/versions/3/onlinedeliverydata.csv\")"
      ],
      "metadata": {
        "id": "38xCjKYpEwek"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To populate the values of order preferrence to Swiggy and Zomato"
      ],
      "metadata": {
        "id": "X3bekS3sKEPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val = ['Zomato', 'Swiggy']\n",
        "for i in df_2['Medium (P1)']:\n",
        "  if str(i) == \"Food delivery apps\":\n",
        "    df_2['Medium (P1)'] = np.random.choice(val, size=len(df_2))"
      ],
      "metadata": {
        "id": "vspwuEdyKH4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the necessary columns from D2."
      ],
      "metadata": {
        "id": "7-Q-wKibKhQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_2 = pd.DataFrame()\n",
        "\n",
        "df_2_columns = ['Age', 'Gender', 'Marital Status', 'Occupation', 'Monthly Income',  'Medium (P1)', 'Meal(P1)', 'Influence of rating', 'Freshness ', 'Temperature', 'Good Taste ', 'Good Quantity', 'Good Food quality', 'Poor Hygiene', 'Bad past experience', 'High Quality of package', 'Late Delivery', 'Long delivery time',  'Delay of delivery person getting assigned', 'Delay of delivery person picking up food', 'Maximum wait time', 'Less Delivery time', 'Wrong order delivered',  'Missing item', 'Order placed by mistake']\n",
        "\n",
        "final_df_2_columns = ['Age', 'Gender', 'Marital_Status', 'Occupation', 'Monthly_Income',  'Order_Preference', 'Meal_Type', 'Influence_of_Rating', 'Freshness_of_Food', 'Temperature_of_Food', 'Taste_of_Food', 'Quantity_of_Food', 'Food_Quality', 'Poor_Hygiene', 'Bad_Past_Experience', 'High_Quality_of_Package', 'Late_Delivery', 'Long_Delivery_Time', 'Delay_of_Delivery_Person_Getting_Assigned', 'Delay_of_Delivery_Person_Picking_Up_Food', 'Maximum_Wait_Time', 'Less_Delivery_Time', 'Wrong_Order_Delivered',  'Missing_Item', 'Order_Placed_by_Mistake' ]\n",
        "\n",
        "final_df_2[final_df_2_columns] = df_2[df_2_columns].copy()"
      ],
      "metadata": {
        "id": "4Mr-q6_RKch0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the Final Dataset"
      ],
      "metadata": {
        "id": "mj2SXf2fKwSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([d1_d3_d4,final_df_2,final_df_5], axis = 1)\n"
      ],
      "metadata": {
        "id": "2fg2NjB7F80U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the ages for the final dataset"
      ],
      "metadata": {
        "id": "j4vlbGQfK_t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = len(final_df)\n",
        "mean_age = 30\n",
        "std_dev = 8  # Standard deviation determines the spread\n",
        "\n",
        "# Generate ages from a normal distribution\n",
        "ages = np.random.normal(loc=mean_age, scale=std_dev, size=num_rows)\n",
        "\n",
        "# Clip ages to ensure they fall within the range 18-59\n",
        "ages = np.clip(ages, 18, 60)\n",
        "\n",
        "# Assign to the DataFrame\n",
        "final_df['Age'] = ages.astype(int)"
      ],
      "metadata": {
        "id": "AjpXE8ijGPVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genrating the Nan values with the previous data which is present on the  original datasets"
      ],
      "metadata": {
        "id": "JuJSYq4_LpSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in final_df.columns:\n",
        "    if col not in ['Order_Id']:\n",
        "      # the replace_nan_values function is on the cleaning dataset file 1,3,4\n",
        "        final_df[col] = replace_nan_values(final_df,final_df[col])"
      ],
      "metadata": {
        "id": "EeQ-_4-xL5CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the final datset with the proper naming conventions of the column name."
      ],
      "metadata": {
        "id": "aiw5qDyXLEt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset =  final_df[['Order_Id','Age','Gender','Marital_Status','Occupation','Monthly_Income', 'Order_Preference',\t'Restaurant_Name'\t,\n",
        "        'City',\t'Area',\t'Cuisine',\t'Veg/Non-Veg',\t'Delivery_Time',\t'Total_Order_Value',\n",
        "      'Meal_Type',\t'Dish_Liked',\t'Average_Rating',\t'Total_Rating_String', \t'Influence_of_Rating',\n",
        "      'Freshness_of_Food', 'Temperature_of_Food',\n",
        "       'Taste_of_Food', 'Quantity_of_Food', 'Food_Quality', 'Poor_Hygiene',\n",
        "       'Bad_Past_Experience', 'High_Quality_of_Package', 'Late_Delivery',\n",
        "       'Long_Delivery_Time', 'Delay_of_Delivery_Person_Getting_Assigned',\n",
        "       'Delay_of_Delivery_Person_Picking_Up_Food', 'Maximum_Wait_Time',\n",
        "       'Less_Delivery_Time', 'Wrong_Order_Delivered', 'Missing_Item',\n",
        "       'Order_Placed_by_Mistake', 'Order_Date', 'Time_Orderd',\n",
        "       'Time_Order_picked', 'Weather_conditions']]\n",
        "Dataset = Dataset.rename(columns={'Order_Preference':'App_Preference','Time_Orderd': 'Order_Time', 'Time_Order_picked': 'Order_Pickup_Time'})"
      ],
      "metadata": {
        "id": "dGKf4YHnGXdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset.to_csv('final_dataset_new.csv', index=False)"
      ],
      "metadata": {
        "id": "uTMdz-00GZud"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}